#!/usr/bin/env bash

# AWS AFT Customizations Pipeline ä¸€è¦§å–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
# AFTã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆ{account-id}-customizations-pipelineï¼‰ã®çŠ¶æ…‹ã‚’
# ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±ã¨çµ„ã¿åˆã‚ã›ã¦è¡¨ç¤º
# aws_cache.sh ã‚’åˆ©ç”¨ã—ã¦APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã€é«˜é€ŸåŒ–ã‚’å®Ÿç¾

set -euo pipefail

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
AWS_CACHE_SCRIPT="$SCRIPT_DIR/aws_cache.sh"
CONFIG_FILE="$SCRIPT_DIR/aot_config.conf"

# aws_cache.shã®å­˜åœ¨ç¢ºèª
if [[ ! -f "$AWS_CACHE_SCRIPT" ]]; then
    echo "âŒ ã‚¨ãƒ©ãƒ¼: aws_cache.sh ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: $AWS_CACHE_SCRIPT" >&2
    echo "ğŸ’¡ ãƒ’ãƒ³ãƒˆ: aws_cache.sh ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®ã—ã¦ãã ã•ã„" >&2
    exit 1
fi

# aws_cache.shãŒå®Ÿè¡Œå¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
if [[ ! -x "$AWS_CACHE_SCRIPT" ]]; then
    echo "âŒ ã‚¨ãƒ©ãƒ¼: aws_cache.sh ã«å®Ÿè¡Œæ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“" >&2
    echo "ğŸ’¡ è§£æ±ºæ–¹æ³•: chmod +x $AWS_CACHE_SCRIPT" >&2
    exit 1
fi

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€é–¢æ•°
load_config() {
    local config_file="$1"
    
    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨
    if [[ ! -f "$config_file" ]]; then
        echo "âš ï¸  è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: $config_file" >&2
        echo "ğŸ’¡ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™ã€‚è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹å ´åˆ:" >&2
        echo "   cp aot_config.example.conf aot_config.conf" >&2
        return 1
    fi
    
    # Bashå¤‰æ•°å½¢å¼ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    # shellcheck source=/dev/null
    source "$config_file"
    return 0
}

# ãƒ˜ãƒ«ãƒ—è¡¨ç¤º
show_help() {
    cat << EOF
AWS AFT Customizations Pipeline ä¸€è¦§å–å¾—

ä½¿ç”¨æ–¹æ³•:
  $0 [ã‚ªãƒ—ã‚·ãƒ§ãƒ³]

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ aws_cache.sh ã‚’åˆ©ç”¨ã—ã¦APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¾ã™ã€‚
AFTã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆ{account-id}-customizations-pipelineï¼‰ã®
çŠ¶æ…‹ã‚’ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±ã¨çµ„ã¿åˆã‚ã›ã¦è¡¨ç¤ºã—ã¾ã™ã€‚

è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«:
  aot_config.conf ã§ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’å¤‰æ›´ã§ãã¾ã™ã€‚
  AWS_ACCOUNTS_PROFILE ã§AWS Organizationsã‚¢ã‚¯ã‚»ã‚¹ç”¨ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚
  AWS_PIPELINES_PROFILE ã§CodePipelineã‚¢ã‚¯ã‚»ã‚¹ç”¨ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚

ã‚ªãƒ—ã‚·ãƒ§ãƒ³:
  -f, --format FORMAT   å‡ºåŠ›å½¢å¼ (table|json|csv) [ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: table]
  -s, --status STATUS   ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ (ALL|Succeeded|Failed|InProgress|Stopped) [ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ALL]
  -c, --cache-ttl TTL   ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ‰åŠ¹æœŸé™ï¼ˆç§’ï¼‰ [ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1800]
  -r, --region REGION   AWSãƒªãƒ¼ã‚¸ãƒ§ãƒ³ [ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ap-northeast-1]
  -d, --debug          ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ï¼ˆaws_cache.shã®ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã‚‚è¡¨ç¤ºï¼‰
  -h, --help           ã“ã®ãƒ˜ãƒ«ãƒ—ã‚’è¡¨ç¤º

ä¾‹:
  $0                           # AFTã‚«ã‚¹ã‚¿ãƒã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä¸€è¦§ã‚’ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§è¡¨ç¤º
  $0 -f json                   # JSONå½¢å¼ã§å‡ºåŠ›
  $0 -f csv                    # CSVå½¢å¼ã§å‡ºåŠ›
  $0 -s Failed                 # å¤±æ•—ã—ãŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ã¿è¡¨ç¤º
  $0 -c 3600 -d               # 1æ™‚é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰
  
ã‚­ãƒ£ãƒƒã‚·ãƒ¥é–¢é€£:
  åˆå›å®Ÿè¡Œæ™‚: AWS APIã‚’å‘¼ã³å‡ºã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
  2å›ç›®ä»¥é™: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰é«˜é€Ÿå–å¾—ï¼ˆTTLæœŸé–“å†…ï¼‰
  å¼·åˆ¶æ›´æ–°: ./aws_cache.sh -f -- aws codepipeline list-pipelines

EOF
}

# ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ã‚½ãƒ¼ãƒˆï¼ˆget_accounts.shã‹ã‚‰æµç”¨ï¼‰
get_sorted_accounts() {
    local status_filter="$1"
    local cache_ttl="$2"
    local debug_flag="$3"
    local aws_profile="$4"
    local show_message="${5:-false}"
    
    local cache_args=("-t" "$cache_ttl")
    if [[ "$debug_flag" == "true" ]]; then
        cache_args+=("-d")
    fi
    
    # aws_cache.sh ã‚’ä½¿ç”¨ã—ã¦AWS Organizations list-accounts ã‚’å®Ÿè¡Œ
    if [[ "$show_message" == "true" ]]; then
        echo "ğŸ” AWS Organizations ã‹ã‚‰ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒªã‚¹ãƒˆã‚’å–å¾—ä¸­..." >&2
    fi
    
    local aws_command=("aws" "organizations" "list-accounts")
    if [[ -n "$aws_profile" && "$aws_profile" != "default" ]]; then
        aws_command+=("--profile" "$aws_profile")
    fi
    
    local accounts_data
    if [[ "$show_message" == "true" ]]; then
        accounts_data=$("$AWS_CACHE_SCRIPT" "${cache_args[@]}" -- "${aws_command[@]}" 2> >(tee /dev/stderr))
    else
        accounts_data=$("$AWS_CACHE_SCRIPT" "${cache_args[@]}" -- "${aws_command[@]}" 2>/dev/null)
    fi
    
    # jqã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã€ã‚½ãƒ¼ãƒˆã€æ•´å½¢
    local jq_filter='.Accounts'
    
    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    if [[ "$status_filter" != "ALL" ]]; then
        jq_filter="$jq_filter | map(select(.Status == \"$status_filter\"))"
    fi
    
    # JoinedTimestampã§ã‚½ãƒ¼ãƒˆ
    jq_filter="$jq_filter | sort_by(.JoinedTimestamp)"
    
    echo "$accounts_data" | jq -r "$jq_filter"
}

# AFTã‚«ã‚¹ã‚¿ãƒã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä¸€è¦§ã‚’å–å¾—
get_aft_pipelines() {
    local cache_ttl="$1"
    local debug_flag="$2"
    local aws_profile="$3"
    local region="$4"
    
    local cache_args=("-t" "$cache_ttl")
    if [[ "$debug_flag" == "true" ]]; then
        cache_args+=("-d")
    fi
    
    local aws_command=("aws" "codepipeline" "list-pipelines")
    if [[ -n "$aws_profile" && "$aws_profile" != "default" ]]; then
        aws_command+=("--profile" "$aws_profile")
    fi
    if [[ -n "$region" ]]; then
        aws_command+=("--region" "$region")
    fi
    
    # AFTã‚«ã‚¹ã‚¿ãƒã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ã¿ã‚’å–å¾—
    aws_command+=("--query" 'pipelines[?ends_with(name, `-customizations-pipeline`)]')
    
    echo "ğŸ” AFTã‚«ã‚¹ã‚¿ãƒã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä¸€è¦§ã‚’å–å¾—ä¸­..." >&2
    
    local pipelines_data
    pipelines_data=$("$AWS_CACHE_SCRIPT" "${cache_args[@]}" --batch-mode -- "${aws_command[@]}")
    
    echo "$pipelines_data"
}

# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è©³ç´°æƒ…å ±ã‚’å–å¾—
get_pipeline_details() {
    local pipeline_name="$1"
    local cache_ttl="$2"
    local debug_flag="$3"
    local aws_profile="$4"
    local region="$5"
    
    local cache_args=("-t" "$cache_ttl")
    if [[ "$debug_flag" == "true" ]]; then
        cache_args+=("-d")
    fi
    
    local aws_command=("aws" "codepipeline" "get-pipeline-state" "--name" "$pipeline_name")
    if [[ -n "$aws_profile" && "$aws_profile" != "default" ]]; then
        aws_command+=("--profile" "$aws_profile")
    fi
    if [[ -n "$region" ]]; then
        aws_command+=("--region" "$region")
    fi
    
    "$AWS_CACHE_SCRIPT" "${cache_args[@]}" -- "${aws_command[@]}" 2>/dev/null
}

# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œå±¥æ­´ã‚’å–å¾—
get_pipeline_executions() {
    local pipeline_name="$1"
    local cache_ttl="$2"
    local debug_flag="$3"
    local aws_profile="$4"
    local region="$5"
    
    local cache_args=("-t" "$cache_ttl")
    if [[ "$debug_flag" == "true" ]]; then
        cache_args+=("-d")
    fi
    
    local aws_command=("aws" "codepipeline" "list-pipeline-executions" "--pipeline-name" "$pipeline_name" "--max-items" "1")
    if [[ -n "$aws_profile" && "$aws_profile" != "default" ]]; then
        aws_command+=("--profile" "$aws_profile")
    fi
    if [[ -n "$region" ]]; then
        aws_command+=("--region" "$region")
    fi
    
    "$AWS_CACHE_SCRIPT" "${cache_args[@]}" -- "${aws_command[@]}" 2>/dev/null
}

# ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§å‡ºåŠ›
format_table() {
    local combined_data="$1"
    local status_filter="$2"
    
    echo "ğŸš€ AWS AFT Customizations Pipeline ä¸€è¦§"
    echo "=============================================================================================================="
    printf "%-16s %-35s %-15s %-20s %-20s\n" "Account ID" "Account Name" "Status" "Last Execution" "Updated"
    echo "=============================================================================================================="
    
    echo "$combined_data" | jq -r --arg status_filter "$status_filter" '
        .[] | 
        select(
            if $status_filter == "ALL" then true
            else (.pipeline_status // "Unknown") == $status_filter
            end
        ) |
        [
            .account_id,
            (.account_name // "N/A"),
            (.pipeline_status // "Unknown"),
            (if .last_execution_time then (.last_execution_time | sub("\\.[0-9]+\\+.*$"; "Z") | sub("\\+.*$"; "Z") | strptime("%Y-%m-%dT%H:%M:%SZ") | strftime("%Y/%m/%d %H:%M:%S")) else "N/A" end),
            (if .pipeline_updated then (.pipeline_updated | sub("\\.[0-9]+\\+.*$"; "Z") | sub("\\+.*$"; "Z") | strptime("%Y-%m-%dT%H:%M:%SZ") | strftime("%Y/%m/%d %H:%M:%S")) else "N/A" end)
        ] | @tsv' | \
    while IFS=$'\t' read -r account_id account_name status last_execution updated; do
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã«å¿œã˜ãŸçµµæ–‡å­—ã‚’è¿½åŠ 
        case "$status" in
            "Succeeded") status_display="âœ… $status" ;;
            "Failed") status_display="âŒ $status" ;;
            "InProgress") status_display="ğŸ”„ $status" ;;
            "Stopped") status_display="â¹ï¸  $status" ;;
            *) status_display="â“ $status" ;;
        esac
        
        printf "%-16s %-35s %-15s %-20s %-20s\n" "$account_id" "$account_name" "$status_display" "$last_execution" "$updated"
    done
    
    echo "=============================================================================================================="
    
    # çµ±è¨ˆæƒ…å ±
    local total_count succeeded_count failed_count inprogress_count stopped_count unknown_count
    total_count=$(echo "$combined_data" | jq 'length')
    succeeded_count=$(echo "$combined_data" | jq 'map(select(.pipeline_status == "Succeeded")) | length')
    failed_count=$(echo "$combined_data" | jq 'map(select(.pipeline_status == "Failed")) | length')
    inprogress_count=$(echo "$combined_data" | jq 'map(select(.pipeline_status == "InProgress")) | length')
    stopped_count=$(echo "$combined_data" | jq 'map(select(.pipeline_status == "Stopped")) | length')
    unknown_count=$(echo "$combined_data" | jq 'map(select(.pipeline_status == null or .pipeline_status == "Unknown")) | length')
    
    echo "ğŸ“ˆ çµ±è¨ˆ: ç·æ•°=$total_count, âœ…æˆåŠŸ=$succeeded_count, âŒå¤±æ•—=$failed_count, ğŸ”„å®Ÿè¡Œä¸­=$inprogress_count, â¹ï¸åœæ­¢=$stopped_count, â“ä¸æ˜=$unknown_count"
}

# JSONå½¢å¼ã§å‡ºåŠ›
format_json() {
    local combined_data="$1"
    local status_filter="$2"
    
    echo "$combined_data" | jq --arg status_filter "$status_filter" '
        map(select(
            if $status_filter == "ALL" then true
            else (.pipeline_status // "Unknown") == $status_filter
            end
        ))'
}

# CSVå½¢å¼ã§å‡ºåŠ›
format_csv() {
    local combined_data="$1"
    local status_filter="$2"
    
    echo "Account ID,Account Name,Pipeline Status,Last Execution,Updated"
    echo "$combined_data" | jq -r --arg status_filter "$status_filter" '
        .[] | 
        select(
            if $status_filter == "ALL" then true
            else (.pipeline_status // "Unknown") == $status_filter
            end
        ) |
        [
            .account_id,
            (.account_name // "N/A"),
            (.pipeline_status // "Unknown"),
            (if .last_execution_time then (.last_execution_time | sub("\\.[0-9]+\\+.*$"; "Z") | sub("\\+.*$"; "Z") | strptime("%Y-%m-%dT%H:%M:%SZ") | strftime("%Y/%m/%d %H:%M:%S")) else "N/A" end),
            (if .pipeline_updated then (.pipeline_updated | sub("\\.[0-9]+\\+.*$"; "Z") | sub("\\+.*$"; "Z") | strptime("%Y-%m-%dT%H:%M:%SZ") | strftime("%Y/%m/%d %H:%M:%S")) else "N/A" end)
        ] | @csv'
}

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
main() {
    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    load_config "$CONFIG_FILE" || true
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤è¨­å®š
    local format="${PIPELINES_DEFAULT_FORMAT:-table}"
    local status_filter="${PIPELINES_DEFAULT_STATUS:-ALL}"
    local cache_ttl="${CACHE_TTL:-1800}"
    local region="${AWS_DEFAULT_REGION:-ap-northeast-1}"
    local aws_accounts_profile="${AWS_ACCOUNTS_PROFILE:-default}"
    local aws_pipelines_profile="${AWS_PIPELINES_PROFILE:-default}"
    local debug_flag="false"
    
    # å¼•æ•°è§£æ
    while [[ $# -gt 0 ]]; do
        case $1 in
            -f|--format)
                format="$2"
                if [[ ! "$format" =~ ^(table|json|csv)$ ]]; then
                    echo "âŒ ã‚¨ãƒ©ãƒ¼: ç„¡åŠ¹ãªå‡ºåŠ›å½¢å¼: $format" >&2
                    echo "æœ‰åŠ¹ãªå½¢å¼: table, json, csv" >&2
                    exit 1
                fi
                shift 2
                ;;
            -s|--status)
                status_filter="$2"
                if [[ ! "$status_filter" =~ ^(ALL|Succeeded|Failed|InProgress|Stopped)$ ]]; then
                    echo "âŒ ã‚¨ãƒ©ãƒ¼: ç„¡åŠ¹ãªã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: $status_filter" >&2
                    echo "æœ‰åŠ¹ãªã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: ALL, Succeeded, Failed, InProgress, Stopped" >&2
                    exit 1
                fi
                shift 2
                ;;
            -c|--cache-ttl)
                cache_ttl="$2"
                if ! [[ "$cache_ttl" =~ ^[0-9]+$ ]]; then
                    echo "âŒ ã‚¨ãƒ©ãƒ¼: TTLã¯æ•°å€¤ã§æŒ‡å®šã—ã¦ãã ã•ã„: $cache_ttl" >&2
                    exit 1
                fi
                shift 2
                ;;
            -r|--region)
                region="$2"
                shift 2
                ;;
            -d|--debug)
                debug_flag="true"
                shift
                ;;
            -h|--help)
                show_help
                exit 0
                ;;
            -*)
                echo "âŒ ã‚¨ãƒ©ãƒ¼: ä¸æ˜ãªã‚ªãƒ—ã‚·ãƒ§ãƒ³: $1" >&2
                show_help
                exit 1
                ;;
            *)
                echo "âŒ ã‚¨ãƒ©ãƒ¼: ä¸æ˜ãªå¼•æ•°: $1" >&2
                show_help
                exit 1
                ;;
        esac
    done
    
    # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±ã‚’å–å¾—ï¼ˆget_accounts.shã‚’ç›´æ¥å‘¼ã³å‡ºã—ï¼‰
    local accounts_json
    accounts_json=$("$SCRIPT_DIR/get_accounts.sh" -f json -s ACTIVE -c "$cache_ttl" 2>/dev/null)
    
    # AFTãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä¸€è¦§ã‚’å–å¾—
    local pipelines_json
    pipelines_json=$(get_aft_pipelines "$cache_ttl" "$debug_flag" "$aws_pipelines_profile" "$region")
    
    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ•°ã‚’ç¢ºèª
    local pipeline_count
    pipeline_count=$(echo "$pipelines_json" | jq 'length')
    
    if [[ "$debug_flag" == "true" ]]; then
        echo "ğŸ” ãƒ‡ãƒãƒƒã‚°: ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ•° = $pipeline_count" >&2
        echo "ğŸ” ãƒ‡ãƒãƒƒã‚°: ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³JSON = $(echo "$pipelines_json" | head -c 200)..." >&2
    fi
    
    if [[ "$pipeline_count" -eq 0 ]]; then
        echo "âš ï¸  AFTã‚«ã‚¹ã‚¿ãƒã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ" >&2
        exit 0
    fi
    
    echo "ğŸ“Š $pipeline_count å€‹ã®AFTãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è©³ç´°æƒ…å ±ã‚’å–å¾—ä¸­..." >&2
    
    # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±ã‚’ãƒãƒƒã‚·ãƒ¥ãƒãƒƒãƒ—å½¢å¼ã§æº–å‚™ï¼ˆé«˜é€Ÿãƒ«ãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®ãŸã‚ï¼‰
    local accounts_lookup
    accounts_lookup=$(echo "$accounts_json" | jq -r 'map({(.Id): .Name}) | add')
    
    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è©³ç´°æƒ…å ±ã‚’ä¸¦åˆ—å–å¾—
    local temp_dir=$(mktemp -d)
    local max_parallel="${PERFORMANCE_MAX_PARALLEL:-10}"
    local current_parallel=0
    local processed=0
    
    local pipeline_names
    pipeline_names=$(echo "$pipelines_json" | jq -r '.[].name')
    
    while IFS= read -r pipeline_name; do
        [[ -z "$pipeline_name" ]] && continue
        
        processed=$((processed + 1))
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼è¡¨ç¤º
        if [[ $((processed % 25)) -eq 0 ]] || [[ $processed -eq $pipeline_count ]]; then
            printf "\râœ… AFTãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è©³ç´°å–å¾—ä¸­ [%d/%d] (%d%%) - %s" "$processed" "$pipeline_count" "$((processed * 100 / pipeline_count))" "$pipeline_name" >&2
        fi
        
        # ä¸¦åˆ—å‡¦ç†åˆ¶é™
        if [[ $current_parallel -ge $max_parallel ]]; then
            wait  # å…¨ã¦ã®ä¸¦åˆ—å‡¦ç†ãŒå®Œäº†ã™ã‚‹ã¾ã§å¾…æ©Ÿ
            current_parallel=0
        fi
        
        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§è©³ç´°æƒ…å ±ã‚’å–å¾—
        {
            # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDã‚’æŠ½å‡º
            local account_id
            account_id=$(echo "$pipeline_name" | sed 's/-customizations-pipeline$//')
            
            # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåã‚’é«˜é€Ÿãƒ«ãƒƒã‚¯ã‚¢ãƒƒãƒ—
            local account_name
            account_name=$(echo "$accounts_lookup" | jq -r --arg account_id "$account_id" '.[$account_id] // "N/A"')
            
            # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è©³ç´°ã‚’å–å¾—
            local pipeline_state pipeline_executions
            pipeline_state=$(get_pipeline_details "$pipeline_name" "$cache_ttl" "$debug_flag" "$aws_pipelines_profile" "$region")
            pipeline_executions=$(get_pipeline_executions "$pipeline_name" "$cache_ttl" "$debug_flag" "$aws_pipelines_profile" "$region")
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
            local pipeline_data
            pipeline_data=$(jq -n \
                --arg account_id "$account_id" \
                --arg account_name "$account_name" \
                --arg pipeline_name "$pipeline_name" \
                --argjson pipeline_state "$pipeline_state" \
                --argjson pipeline_executions "$pipeline_executions" \
                '{
                    account_id: $account_id,
                    account_name: $account_name,
                    pipeline_name: $pipeline_name,
                    pipeline_status: (
                        [$pipeline_state.stageStates[]?.latestExecution?.status] as $statuses |
                        if ($statuses | map(select(. == "InProgress")) | length) > 0 then "InProgress"
                        elif ($statuses | map(select(. == "Failed")) | length) > 0 then "Failed"
                        elif ($statuses | map(select(. == "Stopped")) | length) > 0 then "Stopped"
                        elif ($statuses | map(select(. == "Succeeded")) | length) == ($statuses | length) and ($statuses | length) > 0 then "Succeeded"
                        else "Unknown"
                        end
                    ),
                    pipeline_updated: ($pipeline_state.updated // null),
                    last_execution_time: ($pipeline_executions.pipelineExecutionSummaries[0].lastUpdateTime // null),
                    last_execution_status: ($pipeline_executions.pipelineExecutionSummaries[0].status // null)
                }')
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            echo "$pipeline_data" > "$temp_dir/${processed}.json"
        } &
        
        current_parallel=$((current_parallel + 1))
    done <<< "$pipeline_names"
    
    # æ®‹ã‚Šã®ä¸¦åˆ—å‡¦ç†å®Œäº†ã‚’å¾…æ©Ÿ
    wait
    
    echo "" >&2
    echo "ğŸ”„ çµæœã‚’çµåˆä¸­..." >&2
    
    # çµæœã‚’çµåˆ
    local combined_data="[]"
    if [[ -d "$temp_dir" ]]; then
        combined_data=$(find "$temp_dir" -name "*.json" -exec cat {} \; | jq -s '.')
        rm -rf "$temp_dir"
    fi
    
    echo "âœ… AFTãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è©³ç´°æƒ…å ±ã®å–å¾—ãŒå®Œäº†ã—ã¾ã—ãŸ" >&2
    
    # å‡ºåŠ›å½¢å¼ã«å¿œã˜ã¦è¡¨ç¤º
    case "$format" in
        "table")
            format_table "$combined_data" "$status_filter"
            ;;
        "json")
            format_json "$combined_data" "$status_filter"
            ;;
        "csv")
            format_csv "$combined_data" "$status_filter"
            ;;
    esac
}

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒç›´æ¥å®Ÿè¡Œã•ã‚ŒãŸå ´åˆã®ã¿mainã‚’å‘¼ã³å‡ºã—
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi